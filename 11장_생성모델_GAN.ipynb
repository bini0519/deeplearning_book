{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11장. 생성모델-GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucyKOWIVHnbA"
      },
      "source": [
        "# <목차>\r\n",
        "1. 생성모델의 개념\r\n",
        "2. GAN의 개념\r\n",
        "3. GAN을 이용한 MNIST 데이터 생성\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iokb198H5oR"
      },
      "source": [
        "# 1. 생성모델의 개념\r\n",
        "---\r\n",
        "- 구분모델(Discriminative Model): 분류, 예측하기 위함\r\n",
        "- 생성모델(Generative Model): training data와 유사한 new data 생성하기 위함\r\n",
        "  - 잠재변수(Latent Variable): 데이터에 직접적으로 나타나지 않지만 데이터 분포를 만드는데 영향을 끼침\r\n",
        "  - 동작과정: 잠재변수로부터 적절한 데이터를 생성해내는 함수\r\n",
        "  > x_data = f_GAN (z_noise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkS60QgLIyCg"
      },
      "source": [
        "# 2. GAN의 개념\r\n",
        "---\r\n",
        "**G**enerative **A**dversarial **N**etworks의 약자  \r\n",
        "게임 이론의 minimax two-player 게임의 구조 이용  \r\n",
        "생성자*(Generator)*와 구분자*(Discriminator)*로 구성  \r\n",
        "- 생성자는 원본 데이터와 유사한 **데이터 분포**를 학습\r\n",
        "- 구분자는 50%의 확률로 트레이닝 데이터와 가짜 데이터를 구분\r\n",
        "- 잠재변수 z의 값은 트레이닝 데이터의 분포값 x로 맵핑됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27bubK_IJAa9"
      },
      "source": [
        "# 3. GAN을 이용한 MNIST 데이터 생성\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CGJQQ4cJFcs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "f4e662b0-acc9-452c-daa2-9d6aea24e1b4"
      },
      "source": [
        "!pip install tensorflow==1.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/55/7995cc1e9e60fa37ea90e6777d832e75026fde5c6109215d892aaff2e9b7/tensorflow-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (35.0MB)\n",
            "\u001b[K     |████████████████████████████████| 35.0MB 1.2MB/s \n",
            "\u001b[?25hCollecting backports.weakref==1.0rc1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.19.5)\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 42.0MB/s \n",
            "\u001b[?25hCollecting markdown==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/99/288a81a38526a42c98b5b9832c6e339ca8d5dd38b19a53abfac7c8037c7f/Markdown-2.2.0.tar.gz (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 23.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (0.36.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow==1.2) (51.3.3)\n",
            "Building wheels for collected packages: html5lib, markdown\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107222 sha256=691c22f571cf89b6964bf04f08aaf42a8b23fa0d8b23a41e7a5e953194762666\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "  Building wheel for markdown (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markdown: filename=Markdown-2.2.0-cp36-none-any.whl size=136296 sha256=a9a0784a94479decb8a85c77aaa52db3e2725ba893645cdc67944ce43e2f42f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/52/17/f0af18e3e0ec6fa60b361ffed15b4c3468f6f3bcdb87fbe079\n",
            "Successfully built html5lib markdown\n",
            "\u001b[31mERROR: tensorboard 2.4.1 has requirement markdown>=2.6.8, but you'll have markdown 2.2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: backports.weakref, html5lib, bleach, markdown, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.2.3\n",
            "    Uninstalling bleach-3.2.3:\n",
            "      Successfully uninstalled bleach-3.2.3\n",
            "  Found existing installation: Markdown 3.3.3\n",
            "    Uninstalling Markdown-3.3.3:\n",
            "      Successfully uninstalled Markdown-3.3.3\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 markdown-2.2.0 tensorflow-1.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyE7RKxB-32_"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.gridspec as gridspec\r\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78wZXDYg_FFw",
        "outputId": "59729e94-436a-46fe-c36e-8cc37a63d3b4"
      },
      "source": [
        "#데이터 다운로드\r\n",
        "from tensorflow.examples.tutorials.mnist import input_data\r\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\r\n",
        "\r\n",
        "#이미지를 보여주는 함수\r\n",
        "def plot(sample):\r\n",
        "  fig = plt.figure(figsize=(8,8))\r\n",
        "  gs = gridspec.GridSpec(nrows=8, ncols=8) #다중플롯\r\n",
        "  gs.update(wspace=0.05, hspace=0.05)\r\n",
        "\r\n",
        "  for i, sample in enumerate(samples):\r\n",
        "    ax = plt.subplot(gs[i])\r\n",
        "    plt.axis(\"off\") \r\n",
        "    plt.imshow(sample.reshape(28,28))\r\n",
        "\r\n",
        "  return fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ4lHVR0_oAc"
      },
      "source": [
        "#설정값 선언\r\n",
        "#코드에 직접 입력함\r\n",
        "num_epoch = 100000\r\n",
        "batch_size = 64\r\n",
        "num_input = 28*28\r\n",
        "num_latent_variable = 100 #잠재변수 z의 차원\r\n",
        "num_hidden = 128\r\n",
        "learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Scc0SyD6_0"
      },
      "source": [
        "X= tf.placeholder(tf.float32, shape=[None, 28*28])\r\n",
        "z= tf.placeholder(tf.float32, shape=[None, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOMHzA5GGWxK"
      },
      "source": [
        "#Generator 변수 설정\r\n",
        "#100 -> 128 -> 784\r\n",
        "\r\n",
        "with tf.variable_scope('generator'):\r\n",
        "  #은닉층\r\n",
        "  G_W1 = tf.Variable(tf.random_normal(shape=[100, 128], stddev=5e-2))\r\n",
        "  G_b1 = tf.Variable(tf.constant(0.1, shape=[128]))\r\n",
        "  #출력층\r\n",
        "  G_W2 = tf.Variable(tf.random_normal(shape=[128,28*28], stddev=5e-2))\r\n",
        "  G_b2 = tf.Variable(tf.constant(0.1, shape=[28*28]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiHJfT5FJ16D"
      },
      "source": [
        "#Discriminator 변수 설정\r\n",
        "#784 -> 128 -> 1\r\n",
        "\r\n",
        "with tf.variable_scope('discriminator'):\r\n",
        "  #은닉층\r\n",
        "  D_W1 = tf.Variable(tf.random_normal(shape=[28*28, 128], stddev=5e-2))\r\n",
        "  D_b1 = tf.Variable(tf.constant(0.1, shape=[128]))\r\n",
        "  #출력층\r\n",
        "  D_W2 = tf.Variable(tf.random_normal(shape=[128,1], stddev=5e-2))\r\n",
        "  D_b2 = tf.Variable(tf.constant(0.1, shape=[1])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pAMom3OKX0P"
      },
      "source": [
        "#Generator 생성 함수정의\r\n",
        "#인풋: 잠재변수\r\n",
        "#아웃풋: 생성된 이미지\r\n",
        "\r\n",
        "def build_generator(X):\r\n",
        "  hidden_layer = tf.nn.relu(tf.matmul(X, G_W1) + G_b1)\r\n",
        "  generated_mnist_image = tf.nn.sigmoid(tf.matmul(hidden_layer, G_W2) + G_b2)\r\n",
        "  return generated_mnist_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKMGu9eNLbuC"
      },
      "source": [
        "#Discriminator 생성 함수정의\r\n",
        "#인풋: 인풋 이미지\r\n",
        "#아웃풋: 0/1\r\n",
        "\r\n",
        "def build_discriminator(X):\r\n",
        "  hidden_layer = tf.nn.relu(tf.matmul(X, D_W1) + D_b1)\r\n",
        "  logits = tf.matmul(hidden_layer, D_W2) + D_b2 #sigmoid 실행 전 출력값\r\n",
        "  predicted_value = tf.nn.sigmoid(logits)\r\n",
        "  return predicted_value, logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrxY7l5GMRPe"
      },
      "source": [
        "#Generator 선언\r\n",
        "G = build_generator(z)\r\n",
        "\r\n",
        "#Discriminator 선언\r\n",
        "D_real, D_real_logits = build_discriminator(X)\r\n",
        "D_fake, D_fake_logits = build_discriminator(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQTtHQgnSAPI"
      },
      "source": [
        "#Generator 손실 함수정의\r\n",
        "#log(D(G(z)))\r\n",
        "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, \r\n",
        "                                                                labels=tf.ones_like(D_fake_logits)))\r\n",
        "\r\n",
        "#Discriminator 손실 함수정의\r\n",
        "#log(D(x))\r\n",
        "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\r\n",
        "    logits = D_real_logits,\r\n",
        "    labels = tf.ones_like(D_real_logits)))\r\n",
        "\r\n",
        "#log(1-D(G(z)))\r\n",
        "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\r\n",
        "    logits = D_fake_logits,\r\n",
        "    labels = tf.zeros_like(D_fake_logits)))\r\n",
        "\r\n",
        "#log(D(x)) + log(1-D(G(z)))\r\n",
        "d_loss = d_loss_real + d_loss_fake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plPy54CGdXQO"
      },
      "source": [
        "#파라미터 저장\r\n",
        "tvar = tf.trainable_variables()\r\n",
        "\r\n",
        "gvar = [var\r\n",
        "        for var in tvar\r\n",
        "        if 'generator' in var.name]\r\n",
        "dvar = [var \r\n",
        "        for var in tvar\r\n",
        "        if 'discriminator' in var.name]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "GXoX1PzEd6M0",
        "outputId": "00b38358-f0b6-4414-9854-0aa232834a86"
      },
      "source": [
        "#옵티마이저 저장\r\n",
        "g_train_step = tf.train.AdamOptimizer(0.001).minimize(g_loss, var_list=gvar)\r\n",
        "d_train_step = tf.train.AdamOptimizer(0.001).minimize(d_loss, var_list=dvar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1ea97349bf05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#옵티마이저 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mg_train_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0md_train_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'g_loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aichuYnkee0L"
      },
      "source": [
        "#생성된 이미지 저장\r\n",
        "num_img = 0\r\n",
        "if not os.path.exists('generated_output/'):\r\n",
        "  os.makedirs('generated_output/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "3TPz4BdRfkG6",
        "outputId": "c8d961f2-ab48-4b44-e63a-441f93d48d00"
      },
      "source": [
        "#그래프 실행\r\n",
        "with tf.Session() as sess:\r\n",
        "  sess.run(tf.global_variables_initializer())\r\n",
        "\r\n",
        "  #최적화 시작\r\n",
        "  for i in range(100000):\r\n",
        "    batch_X, _ = mnist.train.next_batch(64)\r\n",
        "    batch_noise = np.random.uniform(-1., 1., [64, 100])\r\n",
        "\r\n",
        "    #500번 반복때마다 생성된 이미지 저장\r\n",
        "    if i % 500 == 0:\r\n",
        "      samples = sess.run(G, feed_dict={z: np.random.uniform(-1., 1., [64, 100])})\r\n",
        "      fig = plot(sample)\r\n",
        "      plt.savefig('generated_output/%s.png' %str(num_img).zfill(3), bbox_inches='tight')\r\n",
        "      num_img += 1\r\n",
        "      plt.close(fig)\r\n",
        "\r\n",
        "      #Generator 최적화, 손실함수\r\n",
        "      _, g_loss_print = sess.run([g_train_step, g_loss], feed_dict={z:batch_noise}) #X 필요없음\r\n",
        "\r\n",
        "      #Discriminator 최적화, 손실함수\r\n",
        "      _, d_loss_print = sess.run([d_train_step, d_loss], feed_dict={X:batch_X, z:batch_noise})\r\n",
        "\r\n",
        "      #100번때마다 출력\r\n",
        "      if i % 100 == 0:\r\n",
        "        print('반복: %d, Generator손실함수: %f, Discriminator손실함수: %f' %(i, g_loss_print, d_loss_print))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bd1edd6ea001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#그래프 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#최적화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
          ]
        }
      ]
    }
  ]
}